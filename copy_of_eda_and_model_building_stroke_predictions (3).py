# -*- coding: utf-8 -*-
"""Copy of EDA and Model Building_Stroke_Predictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OvtlzAlEku8ANSoO-CupVCUlf4ELJzQK

# **Exploratory Data Analysis(EDA) of Stroke Predictions**

**Step 1: Import Python Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#to ignore warnings
import warnings
warnings.filterwarnings('ignore')

"""**Step 2: Reading Dataset**"""

data = pd.read_csv("/content/Dataset.csv")

"""**Step 3: Analyzing the Data**"""

#shape will display the no. of observations(rows) and features(columns) in the dataset
data.shape

#head() will display the top 5 observations of the dataset
data.head()

#tail() will display the last 5 observations in the dataset
data.tail()

#info()  helps to understand the data type and the information about data, including the no. of records in each column, data having null or not null,memory usage of the dataset
data.info()

"""**3.1 Check Duplication**"""

#nunique() based on several unique values in each column and the data description ,
#we can identify the continuous and categorical columns in the data. Duplicated data can be handled or removed based on futher analysis
data.nunique()

"""**3.2 Check Missing Values**"""

#isnull() is widely been in all pre-processing steps to identify null values in the data
#this can impact on the accuracy, and reliability of our analysis.
data.isnull().sum()

#precentage of missing values
(data.isnull().sum()/(len(data)))*100

mean_BMI = data['BMI'].mean()

# Replace null values with the mean
data['BMI'].fillna(mean_BMI, inplace=True)

mode_edu = data['education'].mode()[0]

# Replace null values with the mode
data['education'].fillna(mode_edu, inplace=True)

mode_glucose = data['glucose'].mode()[0]

# Replace null values with the mode
data['glucose'].fillna(mode_glucose, inplace=True)

mode_totCh = data['totChol'].mode()[0]

# Replace null values with the mode
data['totChol'].fillna(mode_edu, inplace=True)

mode_BPMeds = data['BPMeds'].mode()[0]

# Replace null values with the mode
data['BPMeds'].fillna(mode_BPMeds, inplace=True)

mode_cigsPerDay = data['cigsPerDay'].mode()[0]

# Replace null values with the mode
data['cigsPerDay'].fillna(mode_cigsPerDay, inplace=True)

mode_heartRate = data['heartRate'].mode()[0]

# Replace null values with the mode
data['heartRate'].fillna(mode_heartRate, inplace=True)

data.isnull().sum()

"""**Step 4: Statistics Summary**"""

#describe() provides a statistics summary of data belonging to numerical data type such as int, float
data.describe(include='all').T

cat_cols = data.select_dtypes(include=['object']).columns.tolist()
num_cols = data.select_dtypes(include=np.number).columns.tolist()
print("Categrical Variables: ", cat_cols)
print('')
print("Numerical Variables: ", num_cols)

"""**Step 5: EDA Univariate Analysis**

Categorical Variables can be visualized using a Count plot, Bar cahrt, Pie plot, etc.

Numerical Variables can be visualized using Histogram, Boxplot, Density Plot, etc.


In the below fig. a hishtogram and boxplot is used to show the pattern of the variables, as some variables have skewness and outliers.

**Numerical Variables**
"""

#Numerical Variables Data Visualization
# we calculate the skewness,which measures the asymmetry of the distribution.
for col in num_cols:
  print(col)
  print('Skew :',round(data[col].skew(),2))
  plt.figure(figsize=(15,4))
  plt.subplot(1,2,1)
  data[col].hist(grid=False)
  plt.ylabel('count')
  plt.subplot(1,2,2)
  sns.boxplot(x=data[col])
  plt.show()

"""Skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable




*   If the skewness is between -0.5 and 0.5, the distribution is considered approximately symmetric.
*   If the skewness is between -1 and -0.5 (or between 0.5 and 1), the distribution is moderately skewed.
*   If the skewness is less than -1 (or greater than 1), the distribution is highly skewed.

In a normally distributed dataset, skewness is zero, indicating perfect symmetry.
In a not normally distributed, the skewness indicates the direction and degree of asymmetry.

**Categorical Variables**
"""

#Categorical Variables Data Visualization
# here we can gain insights into the distribution of genders and smaoking statuses in the dataset.
fig, axes = plt.subplots(1, 2, figsize = (18, 18))
fig.suptitle('Bar plot for categorical variables in the dataset')
sns.countplot(ax = axes[0], x = 'sex', data = data,
              order = data['sex'].value_counts().index);
sns.countplot(ax = axes[1], x = 'is_smoking', data = data,
              order = data['is_smoking'].value_counts().index);

selected_columnsA = ['age',	'education',	'cigsPerDay',	'BPMeds',	'prevalentStroke',	'prevalentHyp',	'diabetes',	'totChol',	'sysBP',	'diaBP',	'BMI',	'heartRate',	'glucose']

import matplotlib.pyplot as plt
import seaborn as sns
correlation_matrix = data[selected_columnsA].corr()
plt.figure(figsize=(15, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="viridis")
plt.title("Correlation Matrix")
plt.show()

"""Model Building"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn import svm
import seaborn as sns
import matplotlib.pyplot as plt

import pandas as pd
from sklearn.model_selection import train_test_split

data.nunique()

data.isnull().sum()

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from collections import Counter

# Step 1: Load the dataset
data = pd.read_csv('/content/Dataset.csv')

# Step 2: Encode categorical variables (if any)
categorical_columns = data.select_dtypes(include=['object']).columns
label_encoders = {}

for col in categorical_columns:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le

# Step 3: Handle missing values
imputer = SimpleImputer(strategy='most_frequent')  # Impute missing values with the most frequent value
data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

# Step 4: Split features (X) and target (y)
X = data.drop('TenYearCHD', axis=1)
y = data['TenYearCHD']

# Step 5: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Step 6: Apply SMOTE
print("Before SMOTE:", Counter(y_train))  # Check class distribution before SMOTE
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
print("After SMOTE:", Counter(y_train_resampled))  # Check class distribution after SMOTE

# X_train_resampled and y_train_resampled are your balanced training datasets

data

data.isnull().sum()

# Get distinct values from the 'Type of Food' column
distinct_TenYearCHD = data['TenYearCHD'].unique()

print("Distinct values in 'TenYearCHD':", distinct_TenYearCHD)

# Get the counts of each class in the 'TenYearCHD' column
class_counts = data['TenYearCHD'].value_counts()

print("Counts of each class in 'TenYearCHD':")
print(class_counts)

"""HyperParameter Tunning"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Define parameter grid
params_lr = {"C": [0.1, 1, 10], "solver": ["liblinear", "lbfgs"]}

# Perform GridSearchCV
lr = LogisticRegression(random_state=42)
grid_lr = GridSearchCV(lr, params_lr, cv=5, scoring="accuracy", n_jobs=-1)
grid_lr.fit(X_train_resampled, y_train_resampled)

# Best parameters and accuracy
print("Best Parameters (Logistic Regression):", grid_lr.best_params_)
print("Best Score (Logistic Regression):", grid_lr.best_score_)

from sklearn.ensemble import RandomForestClassifier

# Define parameter grid
params_rf = {"n_estimators": [50, 100, 200], "max_depth": [None, 10, 20]}

# Perform GridSearchCV
rf = RandomForestClassifier(random_state=42)
grid_rf = GridSearchCV(rf, params_rf, cv=5, scoring="accuracy", n_jobs=-1)
grid_rf.fit(X_train_resampled, y_train_resampled)

# Best parameters and accuracy
print("Best Parameters (Random Forest):", grid_rf.best_params_)
print("Best Score (Random Forest):", grid_rf.best_score_)

from sklearn.neighbors import KNeighborsClassifier

# Define parameter grid
params_knn = {"n_neighbors": [3, 5, 7, 9], "weights": ["uniform", "distance"]}

# Perform GridSearchCV
knn = KNeighborsClassifier()
grid_knn = GridSearchCV(knn, params_knn, cv=5, scoring="accuracy", n_jobs=-1)
grid_knn.fit(X_train_resampled, y_train_resampled)

# Best parameters and accuracy
print("Best Parameters (KNN):", grid_knn.best_params_)
print("Best Score (KNN):", grid_knn.best_score_)

from sklearn.tree import DecisionTreeClassifier

# Define parameter grid
params_dt = {"criterion": ["gini", "entropy"], "max_depth": [None, 10, 20]}

# Perform GridSearchCV
dt = DecisionTreeClassifier(random_state=42)
grid_dt = GridSearchCV(dt, params_dt, cv=5, scoring="accuracy", n_jobs=-1)
grid_dt.fit(X_train_resampled, y_train_resampled)

# Best parameters and accuracy
print("Best Parameters (Decision Tree):", grid_dt.best_params_)
print("Best Score (Decision Tree):", grid_dt.best_score_)

"""MODELS"""

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt



# Example: Logistic Regression with best parameters
best_lr = LogisticRegression(C=10, solver="liblinear", random_state=42)
best_lr.fit(X_train_resampled, y_train_resampled)
y_pred_lr = best_lr.predict(X_test)

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.title("Logistic Regression - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Classification report
print(classification_report(y_test, y_pred_lr))

# Example: Random Forest with best parameters
best_rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)  # Replace with best parameters
best_rf.fit(X_train_resampled, y_train_resampled)
y_pred_rf = best_rf.predict(X_test)


# Confusion matrix
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(conf_matrix_rf, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.title("Random Forest - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Classification report
print(classification_report(y_test, y_pred_rf))

# Example: KNN with best parameters
best_knn = KNeighborsClassifier(n_neighbors=3, weights="distance")  # Replace with best parameters
best_knn.fit(X_train_resampled, y_train_resampled)
y_pred_knn = best_knn.predict(X_test)


# Confusion matrix
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)
sns.heatmap(conf_matrix_knn, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.title("K-Nearest Neighbors - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Classification report
print(classification_report(y_test, y_pred_knn))

# Example: Decision Tree with best parameters
best_dt = DecisionTreeClassifier(criterion="entropy", max_depth=10, random_state=42)
best_dt.fit(X_train_resampled, y_train_resampled)
y_pred_dt = best_dt.predict(X_test)


# Confusion matrix
conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(conf_matrix_dt, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.title("Decision Tree - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Classification report
print(classification_report(y_test, y_pred_dt))

# Example: Gaussian Naive Bayes
best_gnb = GaussianNB()
best_gnb.fit(X_train_resampled, y_train_resampled)
y_pred_gnb = best_gnb.predict(X_test)


# Confusion matrix
conf_matrix_gnb = confusion_matrix(y_test, y_pred_gnb)
sns.heatmap(conf_matrix_gnb, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.title("Gaussian Naive Bayes - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Classification report
print(classification_report(y_test, y_pred_gnb))

from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Initialize XGBoost model
xgb_model = XGBClassifier(random_state=42, scale_pos_weight=len(y_train_resampled[y_train_resampled == 0]) / len(y_train_resampled[y_train_resampled == 1]))

# Fit the model
xgb_model.fit(X_train_resampled, y_train_resampled)

# Make predictions
y_pred = xgb_model.predict(X_test)

# Evaluate the model
print("XGBoost Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Confusion Matrix
conf_matrix_xgb = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix_xgb, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.title("XGBoost - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

import matplotlib.pyplot as plt

# Visualizing the class distribution in y_train (before resampling)
plt.figure(figsize=(6, 4))
pd.Series(y_train).value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])
plt.title("Class Distribution before Resampling")
plt.xlabel("Classes")
plt.ylabel("Count")
plt.show()

# Visualizing the class distribution in y_train_resampled (after resampling)
plt.figure(figsize=(6, 4))
pd.Series(y_train_resampled).value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])
plt.title("Class Distribution after SMOTE")
plt.xlabel("Classes")
plt.ylabel("Count")
plt.show()

"""**Handle Class Imbalance and Model Building**"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay
from imblearn.under_sampling import RandomUnderSampler

# Load your dataset
data = pd.read_csv("/content/Dataset.csv")

data.head()

# Get data types of each column
print("\nData Types of Each Column:")
print(data.dtypes)

# For each column, check if it's numerical and print categories if not
for col in data.columns:
    if pd.api.types.is_numeric_dtype(data[col]):
        print(f"{col} is numerical")
    else:
        print(f"{col} is categorical with categories:")
        print(data[col].unique())

# Convert 'sex' and 'is_smoking' to numerical using label encoding
data['sex'] = data['sex'].map({'F': 0, 'M': 1})
data['is_smoking'] = data['is_smoking'].map({'NO': 0, 'YES': 1})

data

data.isnull().sum()

# Fill missing values with mean for each column
data = data.fillna(data.mean(numeric_only=True))

data.isnull().sum()

data

# Get the counts of each class in the 'TenYearCHD' column
class_counts = data['TenYearCHD'].value_counts()

print("Counts of each class in 'TenYearCHD':")
print(class_counts)

# Separate features (X) and target variable (y)
X = data.drop('TenYearCHD', axis=1)  # Replace 'TenYearCHD' with your target column name
y = data['TenYearCHD']

# Split the data into training and testing sets (stratify ensures balanced class distribution in splits)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Apply SMOTE for oversampling the minority class
#oversample = SMOTE(random_state=42)
#X_resampled, y_resampled = oversample.fit_resample(X_train, y_train)

# Apply RandomUnderSampler to balance the dataset
undersample = RandomUnderSampler(sampling_strategy=1.0, random_state=42)
X_resampled, y_resampled = undersample.fit_resample(X_train, y_train)

# Display the new class distribution
print("Counts of each class after undersampling:")
print(pd.Series(y_resampled).value_counts())

# Scale the features
scaler = StandardScaler()
X_resampled = scaler.fit_transform(X_resampled)
X_test = scaler.transform(X_test)

# Train a Random Forest Classifier
rf_model = RandomForestClassifier(random_state=42, n_estimators=100)
rf_model.fit(X_resampled, y_resampled)

# Evaluate the model
y_pred = rf_model.predict(X_test)
print("\nRandom Forest Performance on Test Data:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("ROC-AUC Score:", roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]))

# Evaluate the model
print("Classification Report:")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"\nROC-AUC Score: {roc_auc:.4f}")

# Plot the ROC Curve
RocCurveDisplay.from_estimator(model, X_test_scaled, y_test)

"""NEWWWWWWWWWWWWWWWWW"""

print(df.columns)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# Load the dataset
file_path = "/content/Dataset.xlsx"  # Replace with your file path
df = pd.read_excel(file_path)

# Display the first few rows and summary
print(df.head())
print(df.info())
print(df.describe())

# Check for missing values
print("Missing Values:\n", df.isnull().sum())

# Check the class distribution for the target variable
print("Class Distribution:\n", df['TenYearCHD'].value_counts())

# Handling missing values
# For numerical columns, use mean/mode imputation
for col in df.select_dtypes(include=['float64', 'int64']).columns:
    df[col].fillna(df[col].mean(), inplace=True)

# For categorical columns, use mode imputation
for col in df.select_dtypes(include=['object']).columns:
    df[col].fillna(df[col].mode()[0], inplace=True)

# Verify no missing values remain
print("Missing Values After Imputation:\n", df.isnull().sum())

# Separate features and target
X = df.drop('TenYearCHD', axis=1)  # Drop target variable
y = df['TenYearCHD']               # Target variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

# Step 1: Check for categorical columns
print(X_train.dtypes)

# Step 2: Handle missing values (if any) in categorical and numeric columns
numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X_train.select_dtypes(include=['object']).columns

# Impute missing values
numeric_imputer = SimpleImputer(strategy='mean')
categorical_imputer = SimpleImputer(strategy='most_frequent')

X_train[numeric_cols] = numeric_imputer.fit_transform(X_train[numeric_cols])
X_train[categorical_cols] = categorical_imputer.fit_transform(X_train[categorical_cols])

# Step 3: Encode categorical columns
# Using OneHotEncoding for categorical variables
if not categorical_cols.empty:
    ct = ColumnTransformer(transformers=[
        ('encoder', OneHotEncoder(drop='first'), categorical_cols)
    ], remainder='passthrough')
    X_train = ct.fit_transform(X_train)

# Convert to a DataFrame (if required for interpretability)
X_train = pd.DataFrame(X_train)

# Step 4: Apply SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Step 5: Check class distribution after SMOTE
print("Class Distribution After SMOTE:\n", pd.Series(y_train_smote).value_counts())

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

# Step 1: Handle missing values for X_test
X_test[numeric_cols] = numeric_imputer.transform(X_test[numeric_cols])
X_test[categorical_cols] = categorical_imputer.transform(X_test[categorical_cols])

# Step 2: Encode categorical columns for X_test
X_test = ct.transform(X_test)  # Use the same ColumnTransformer (`ct`) from X_train

# Step 3: Standardize both train and test sets
X_train_smote = scaler.fit_transform(X_train_smote)
X_test = scaler.transform(X_test)

# Convert back to DataFrame for interpretability (optional)
X_train_smote = pd.DataFrame(X_train_smote)
X_test = pd.DataFrame(X_test)

# Standardize the features
scaler = StandardScaler()
X_train_smote = scaler.fit_transform(X_train_smote)
X_test = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report

# Train Logistic Regression
log_reg = LogisticRegression(random_state=42)
log_reg.fit(X_train_smote, y_train_smote)

# Predict and evaluate
y_pred = log_reg.predict(X_test)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier

# Train Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_smote, y_train_smote)

# Predict and evaluate
y_pred_rf = rf.predict(X_test)
print("Confusion Matrix for Random Forest:\n", confusion_matrix(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

from sklearn.model_selection import GridSearchCV

# Example: Hyperparameter tuning for Random Forest
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
}

grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_smote, y_train_smote)

print("Best Parameters:\n", grid_search.best_params_)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report

# Train the model with the best parameters
best_rf = RandomForestClassifier(
    max_depth=None,
    min_samples_split=2,
    n_estimators=200,
    random_state=42
)
best_rf.fit(X_train_smote, y_train_smote)

# Step 2: Make Predictions on the Test Set
y_pred = best_rf.predict(X_test)

# Step 3: Evaluate the Model
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# Plot confusion matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Random Forest with Best Parameters')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Example: Heatmap for Logistic Regression
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Logistic Regression')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()